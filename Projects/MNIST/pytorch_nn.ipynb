{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afcc7f3e-8127-44c9-8fb0-a6c46dcd5f86",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a328b68",
   "metadata": {},
   "source": [
    "## Importowanie bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bf356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import config_test\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5fc25",
   "metadata": {},
   "source": [
    "## Wybór urządzenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685a13a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" # PyTorch pozwala na wybranie urządzenia, na którym będą przeprowadzane operacje\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f2d20",
   "metadata": {},
   "source": [
    "## Sieć neuronowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33dd2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(784, 256), # wastwa wejściowa (784 neurony) -> warstwa ukryta (256 neuronów)\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, 256), # warstwa ukryta (256 neuronów) -> warstwa ukryta (256 neuronów)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10), # warstwa ukryta (256 neuronów) -> wartswa wyjściowa (10 neuronów) \n",
    "        )\n",
    "\n",
    "    def forward(self, x): # przesuwamy się z warstwy do warstwy\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b31da",
   "metadata": {},
   "source": [
    "## Dostosowanie danych, trenowanie i testowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9a6bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0163910608887672, Accuracy: 0.9025\n",
      "Epoch 2/10, Loss: 0.17150246965885163, Accuracy: 0.9335\n",
      "Epoch 3/10, Loss: 0.10580987068265676, Accuracy: 0.936\n",
      "Epoch 4/10, Loss: 0.07617094045504928, Accuracy: 0.9325\n",
      "Epoch 5/10, Loss: 0.0908170979609713, Accuracy: 0.945\n",
      "Epoch 6/10, Loss: 0.06007138892263174, Accuracy: 0.937\n",
      "Epoch 7/10, Loss: 0.0736413908386603, Accuracy: 0.9415\n",
      "Epoch 8/10, Loss: 0.07056491583457682, Accuracy: 0.9415\n",
      "Epoch 9/10, Loss: 0.07431045561283826, Accuracy: 0.9345\n",
      "Epoch 10/10, Loss: 0.07307876492175273, Accuracy: 0.9445\n",
      "Epoch 1/10, Loss: 1.0571453796625137, Accuracy: 0.922\n",
      "Epoch 2/10, Loss: 0.15037720242142677, Accuracy: 0.9325\n",
      "Epoch 3/10, Loss: 0.10363032282143832, Accuracy: 0.9335\n",
      "Epoch 4/10, Loss: 0.08843611774593592, Accuracy: 0.9295\n",
      "Epoch 5/10, Loss: 0.09193523762747645, Accuracy: 0.9405\n",
      "Epoch 6/10, Loss: 0.0364772818335332, Accuracy: 0.95\n",
      "Epoch 7/10, Loss: 0.03916223005065694, Accuracy: 0.9405\n",
      "Epoch 8/10, Loss: 0.0907833192194812, Accuracy: 0.935\n",
      "Epoch 9/10, Loss: 0.0637108184369281, Accuracy: 0.9305\n",
      "Epoch 10/10, Loss: 0.07729807502240874, Accuracy: 0.949\n",
      "Epoch 1/10, Loss: 1.034036329805851, Accuracy: 0.908\n",
      "Epoch 2/10, Loss: 0.17267519666254522, Accuracy: 0.9195\n",
      "Epoch 3/10, Loss: 0.08664939335361123, Accuracy: 0.941\n",
      "Epoch 4/10, Loss: 0.08392361534014345, Accuracy: 0.934\n",
      "Epoch 5/10, Loss: 0.0777685882858932, Accuracy: 0.9415\n",
      "Epoch 6/10, Loss: 0.05419854727946222, Accuracy: 0.949\n",
      "Epoch 7/10, Loss: 0.07122620813269168, Accuracy: 0.9425\n",
      "Epoch 8/10, Loss: 0.10358704337198288, Accuracy: 0.938\n",
      "Epoch 9/10, Loss: 0.09343300530407578, Accuracy: 0.9445\n",
      "Epoch 10/10, Loss: 0.05527315729670226, Accuracy: 0.948\n",
      "Epoch 1/10, Loss: 0.9954957102537155, Accuracy: 0.919\n",
      "Epoch 2/10, Loss: 0.18051173812150956, Accuracy: 0.9395\n",
      "Epoch 3/10, Loss: 0.10114764454215765, Accuracy: 0.935\n",
      "Epoch 4/10, Loss: 0.07591856357455254, Accuracy: 0.9405\n",
      "Epoch 5/10, Loss: 0.09366457240376622, Accuracy: 0.938\n",
      "Epoch 6/10, Loss: 0.09333429146185518, Accuracy: 0.925\n",
      "Epoch 7/10, Loss: 0.08787408044189214, Accuracy: 0.953\n",
      "Epoch 8/10, Loss: 0.0695627660076134, Accuracy: 0.943\n",
      "Epoch 9/10, Loss: 0.05338551238551736, Accuracy: 0.9475\n",
      "Epoch 10/10, Loss: 0.0785732888567727, Accuracy: 0.95\n",
      "Epoch 1/10, Loss: 1.0193150194883347, Accuracy: 0.907\n",
      "Epoch 2/10, Loss: 0.1814921056330204, Accuracy: 0.925\n",
      "Epoch 3/10, Loss: 0.1196428044885397, Accuracy: 0.9415\n",
      "Epoch 4/10, Loss: 0.06470761929638684, Accuracy: 0.929\n",
      "Epoch 5/10, Loss: 0.06682680461741984, Accuracy: 0.9335\n",
      "Epoch 6/10, Loss: 0.07437190225161612, Accuracy: 0.9395\n",
      "Epoch 7/10, Loss: 0.06223354461579583, Accuracy: 0.9335\n",
      "Epoch 8/10, Loss: 0.09213424698356538, Accuracy: 0.928\n",
      "Epoch 9/10, Loss: 0.07445187931903638, Accuracy: 0.928\n",
      "Epoch 10/10, Loss: 0.08515959734469652, Accuracy: 0.943\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(config_test.NEW_DATA_PATH) #jednym z lepszych sposobów na wrzucenie danych do tensorów jest użycie dataframe\n",
    "\n",
    "# Przechodzimy po kolei po wszystkich foldach\n",
    "for fold in range(config_test.FOLDS_COUNT):\n",
    "    \n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~inicjalizacja danych~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    torch_model = NeuralNetwork().to(device) # model\n",
    "    \n",
    "    # dzielimy nasze dane na treningowe i testowe\n",
    "    df_train = df.loc[df['kfold'] != fold] # dane treningowe = dane, które nie należą do obecnego folda\n",
    "    df_test = df.loc[df['kfold'] == fold] # dane testowe = dane, które należą do obecnego folda\n",
    "\n",
    "    # wypisujemy liczbę wierszy i kolumn\n",
    "    # liczba wierszy powinna wynosić łącznie 10000, bo tyle mamy obrazków\n",
    "    # liczba kolumn powinna wynosić łącznie 28*28 + 2 (liczba pikseli jednego obrazka + kolumna label i kolumna kfold)\n",
    "    #print(df_train.shape)\n",
    "    #print(df_test.shape)\n",
    "\n",
    "    # zamieniamy dataframe na tensory\n",
    "    t_train = torch.tensor(df_train.values, dtype=torch.float32)\n",
    "    t_test = torch.tensor(df_test.values, dtype=torch.float32)\n",
    "    \n",
    "    # dzielimy dane na dane bez labeli i labele\n",
    "    # żeby przeprowadzanie operacji na tensorach było możliwe, to dane bez labeli muszą być zmiennoprzecinkowe, a labele całkowite\n",
    "    t_train_label = t_train[:,-2:-1]\n",
    "    t_train = t_train[:,:-2] # tensor treningowy zawierający 28*28 kolumn\n",
    "    t_train_label = t_train_label.long() # tensor treningowy zawierający kolumnę label\n",
    "    #print(t_train.shape)\n",
    "    #print(t_train_label.shape)\n",
    "\n",
    "    t_test_label = t_test[:,-2:-1]\n",
    "    t_test = t_test[:,:-2] # tensor testowy zawierający 28*28 kolumn\n",
    "    t_test_label = t_test_label.long() # tensor testowy zawierający kolumnę label\n",
    "    #print(t_test.shape)\n",
    "    #print(t_test_label.shape)\n",
    "    \n",
    "    # DataLoader ułatwia dostęp do danych, ładuje dane w określonych partiach (batchach) i losowo miesza dane w każdej epoce\n",
    "    train_dataset = TensorDataset(t_train, t_train_label) # Dataset łączy dane dla DataLoadera\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    test_dataset = TensorDataset(t_test, t_test_label)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # przenosimy tensory do urządzenia\n",
    "    t_train, t_train_label = t_train.to(device), t_train_label.to(device)\n",
    "    t_test, t_test_label = t_test.to(device), t_test_label.to(device)\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~koniec inicjalizacji danych~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~trenowanie danych~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  # Funkcja kosztu dla klasyfikacji\n",
    "    optimizer = torch.optim.Adam(torch_model.parameters(), lr=0.001)  # Dostosowuje parametry modelu\n",
    "\n",
    "    # ustawiamy ziarno generatora liczb losowych, losowe funkcje w PyTorch będą się zachowywać deterministycznie\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # liczba epok\n",
    "    epochs = 10\n",
    "\n",
    "    # pętla treningowa\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ustawienie modelu w tryb treningowy\n",
    "        torch_model.train()\n",
    "\n",
    "        # oblicza straty, które powstały w trakcie trenowania modelu\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader: #X_batch - batch z t_train, y_batch - batch z t_train_label\n",
    "            logits = torch_model(X_batch) # przekazujemy batch danych z t_train do modelu i otrzymujemy logity\n",
    "            y_batch = y_batch.squeeze(1) # usuwamy zbędny wymiar (konieczne dla następnej funkcji)\n",
    "            loss = criterion(logits, y_batch) # obliczamy stratę pomiędzy przewidywaniami modelu a labels\n",
    "\n",
    "            # czyszczenie poprzednich gradientów\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # aktualizacja wag\n",
    "            optimizer.step()\n",
    "\n",
    "            # do strat dodajemy wartość obliczoną przez criterion\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~testowanie danych ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        # ustawienie modelu w tryb oceny\n",
    "        torch_model.eval()\n",
    "        correct = 0 # poprawnie odgadnięte cyfry\n",
    "        total = 0 # wszystkie cyfry\n",
    "        val_loss = 0 # wartość straty\n",
    "\n",
    "        with torch.no_grad(): # wyłączenie liczenia gradientów\n",
    "            for X_val, y_val in test_loader: # X_val - batch z t_test, y_val - batch z t_test_label \n",
    "                logits = torch_model(X_val) # przekazujemy batch danych z t_test do modelu i otrzymujemy logity\n",
    "                y_val = y_val.squeeze(1) # usuwamy dimensions o rozmiarze 1 (konieczne dla następnej funkcji)\n",
    "                loss = criterion(logits, y_val) # obliczamy stratę pomiędzy przewidywaniami modelu a labels\n",
    "                val_loss += loss.item() # do strat dodajemy wartość obliczoną przez criterion\n",
    "\n",
    "                pred = logits.argmax(dim=1) # uzyskujemy indeks klasy przewidywanej\n",
    "                correct += (pred == y_val).sum().item() # sumujemy liczbę poprawnych przewidywań\n",
    "                total += y_val.size(0) #zwiększamy całkowitą liczbę przykładów\n",
    "\n",
    "        accuracy = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}, Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e378e1-496c-4520-a923-996d5afd1de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
